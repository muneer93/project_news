{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1c2cda7-080c-4e72-b3b8-1d025b8b72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "285e2550-0d9f-4794-b4b9-2ebf74fa8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "class YouTubeAPIClient:\n",
    "    def __init__(self):\n",
    "        # Load and clean keys\n",
    "        keys = os.getenv(\"YOUTUBE_API_KEYS\")\n",
    "        if not keys:\n",
    "            raise ValueError(\"No API keys found in file.\")\n",
    "        self.api_keys = [key.strip() for key in keys.split(',')]\n",
    "        self.index = 0\n",
    "        self.youtube = self._build_client(self.api_keys[self.index])\n",
    "\n",
    "    def _build_client(self, key):\n",
    "        return build(\"youtube\", \"v3\", developerKey=key)\n",
    "\n",
    "    def _rotate_key(self):\n",
    "        self.index += 1\n",
    "        if self.index >= len(self.api_keys):\n",
    "            raise Exception(\"All API keys exhausted.\")\n",
    "        print(f\"Switching to next API key: {self.api_keys[self.index]}\")\n",
    "        self.youtube = self._build_client(self.api_keys[self.index])\n",
    "\n",
    "    def execute(self, request):\n",
    "        while True:\n",
    "            try:\n",
    "                return request.execute()\n",
    "            except HttpError as e:\n",
    "                error_res = e.resp.get('status')\n",
    "                if error_res == 403 and 'quotaExceeded' in str(e):\n",
    "                    print(f\"Quota exhausted for API key {self.api_keys[self.index]}\")\n",
    "                    self._rotate_key()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    def get_client(self):\n",
    "        return self.youtube\n",
    "\n",
    "yt_client = YouTubeAPIClient()\n",
    "youtube = yt_client.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ead40e7-0fad-4edb-a2ac-444aadad612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Search for News Channels\n",
    "def search_news_channels(max_results=100):\n",
    "    try:\n",
    "        request = youtube.search().list(\n",
    "            part='snippet',\n",
    "            type='channel',\n",
    "            q='news',\n",
    "            regionCode='US',\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return [(item['snippet']['channelId'], item['snippet']['channelTitle']) for item in response['items']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching news channels: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44a0f5ad-0472-42a8-8c82-7ca2717132cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get Channel Statistics\n",
    "def get_channel_stats(channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part='snippet,statistics',\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        data = response['items'][0]\n",
    "        stats = data['statistics']\n",
    "        return {\n",
    "            'channel_id': channel_id,\n",
    "            'channel_title': data['snippet']['title'],\n",
    "            'subscriber_count': int(stats.get('subscriberCount', 0)),\n",
    "            'total_views': int(stats.get('viewCount', 0)),\n",
    "            'video_count': int(stats.get('videoCount', 0))\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting channel stats for {channel_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5b74ee9-0654-4355-98dc-1c661d811614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get Uploads Playlist ID\n",
    "def get_uploads_playlist_id(channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part='contentDetails',\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting uploads playlist for {channel_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4b4d2663-6e9a-4252-b04e-3ac85b7b581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Get Latest Video IDs\n",
    "def get_latest_video_ids(playlist_id, max_videos=5):\n",
    "    video_ids = []\n",
    "    try:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=max_videos\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting video IDs from playlist {playlist_id}: {e}\")\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "575fc780-547a-4d46-9c31-94c19efd3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Get Video Metadata\n",
    "def get_video_stats(video_id):\n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,statistics',\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        data = response['items'][0]\n",
    "        stats = data['statistics']\n",
    "        return {\n",
    "            'video_id': video_id,\n",
    "            'video_title': data['snippet']['title'],\n",
    "            'video_published_at': data['snippet']['publishedAt'],\n",
    "            'video_views': int(stats.get('viewCount', 0)),\n",
    "            'video_likes': int(stats.get('likeCount', 0)),\n",
    "            'video_comments': int(stats.get('commentCount', 0))\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting stats for video {video_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "27bc9f79-fe5a-43b6-846d-84e060e89e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run the full pipeline ===\n",
    "def get_top_news_videos():\n",
    "    final_data = []\n",
    "    channels = search_news_channels(max_results=100)\n",
    "\n",
    "    for channel_id, channel_title in channels:\n",
    "        channel_info = get_channel_stats(channel_id)\n",
    "        if not channel_info:\n",
    "            continue\n",
    "\n",
    "        uploads_playlist = get_uploads_playlist_id(channel_id)\n",
    "        if not uploads_playlist:\n",
    "            continue\n",
    "\n",
    "        video_ids = get_latest_video_ids(uploads_playlist, max_videos=5)\n",
    "        for vid in video_ids:\n",
    "            video_info = get_video_stats(vid)\n",
    "            if video_info:\n",
    "                final_data.append({\n",
    "                    **channel_info,\n",
    "                    **video_info\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5f6af252-f191-43f0-b8f0-4f25a5e8b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting video IDs from playlist UUYfdidRxbB8Qhf0Nx7ioOYw: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=UUYfdidRxbB8Qhf0Nx7ioOYw&maxResults=5&key=AIzaSyA2fHh7U-Q2qlvBBaBi2D59qvgaxBM6yyY&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n",
      "Error getting video IDs from playlist UUEl0qh9X3kuL1RdFHng497Q: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=UUEl0qh9X3kuL1RdFHng497Q&maxResults=5&key=AIzaSyA2fHh7U-Q2qlvBBaBi2D59qvgaxBM6yyY&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n",
      "Error getting video IDs from playlist UUcE169gw8kJCzyCJZXb7DQw: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=UUcE169gw8kJCzyCJZXb7DQw&maxResults=5&key=AIzaSyA2fHh7U-Q2qlvBBaBi2D59qvgaxBM6yyY&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n",
      "Error getting video IDs from playlist UUXnlcG2bJz5C85RHuYs4pDA: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=UUXnlcG2bJz5C85RHuYs4pDA&maxResults=5&key=AIzaSyA2fHh7U-Q2qlvBBaBi2D59qvgaxBM6yyY&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n",
      "Error getting video IDs from playlist UUn371zWk5jljg-ycIXkEUSA: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&playlistId=UUn371zWk5jljg-ycIXkEUSA&maxResults=5&key=AIzaSyA2fHh7U-Q2qlvBBaBi2D59qvgaxBM6yyY&alt=json returned \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\". Details: \"[{'message': \"The playlist identified with the request's <code>playlistId</code> parameter cannot be found.\", 'domain': 'youtube.playlistItem', 'reason': 'playlistNotFound', 'location': 'playlistId', 'locationType': 'parameter'}]\">\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>total_views</th>\n",
       "      <th>video_count</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "      <th>video_views</th>\n",
       "      <th>video_likes</th>\n",
       "      <th>video_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCuTAXTexrhetbOe3zgskJBQ</td>\n",
       "      <td>日テレNEWS</td>\n",
       "      <td>2780000</td>\n",
       "      <td>4050252948</td>\n",
       "      <td>72293</td>\n",
       "      <td>gBBdYhfWzKI</td>\n",
       "      <td>米中関税協議で共同声明「１１５％引き下げ」合意の背景▽協議出席者の顔ぶれから見える双方の思惑...</td>\n",
       "      <td>2025-05-13T02:00:06Z</td>\n",
       "      <td>283</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCuTAXTexrhetbOe3zgskJBQ</td>\n",
       "      <td>日テレNEWS</td>\n",
       "      <td>2780000</td>\n",
       "      <td>4050252948</td>\n",
       "      <td>72293</td>\n",
       "      <td>ZjwyCwbjdjU</td>\n",
       "      <td>【最新 ニュースライブ】最新ニュースと生活情報（5月13日） ──THE LATEST NE...</td>\n",
       "      <td>2025-05-13T00:35:07Z</td>\n",
       "      <td>1482</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCuTAXTexrhetbOe3zgskJBQ</td>\n",
       "      <td>日テレNEWS</td>\n",
       "      <td>2780000</td>\n",
       "      <td>4050252948</td>\n",
       "      <td>72293</td>\n",
       "      <td>vDoUL0qyV-g</td>\n",
       "      <td>【国会中継】『参議院・財政金融委員会』チャットで語ろう！ ──政治ニュースライブ［2025年...</td>\n",
       "      <td>2025-05-12T09:56:19Z</td>\n",
       "      <td>1381</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCuTAXTexrhetbOe3zgskJBQ</td>\n",
       "      <td>日テレNEWS</td>\n",
       "      <td>2780000</td>\n",
       "      <td>4050252948</td>\n",
       "      <td>72293</td>\n",
       "      <td>MDFwyS8eyg0</td>\n",
       "      <td>【朝 ニュースライブ】最新ニュースと生活情報（5月13日） ──THE LATEST NEW...</td>\n",
       "      <td>2025-05-13T01:46:39Z</td>\n",
       "      <td>62472</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCuTAXTexrhetbOe3zgskJBQ</td>\n",
       "      <td>日テレNEWS</td>\n",
       "      <td>2780000</td>\n",
       "      <td>4050252948</td>\n",
       "      <td>72293</td>\n",
       "      <td>ey8gEkH3D3U</td>\n",
       "      <td>【コメ価格】18週ぶり下落 「備蓄米」効果は？  社員にコメ配布の企業も</td>\n",
       "      <td>2025-05-12T23:14:19Z</td>\n",
       "      <td>938</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>UC69SwnuvoumrKy6giA6crnA</td>\n",
       "      <td>Bad News Reunion - Topic</td>\n",
       "      <td>44</td>\n",
       "      <td>19938</td>\n",
       "      <td>109</td>\n",
       "      <td>GDHq0xd8xQo</td>\n",
       "      <td>Young Girl Blues (Live)</td>\n",
       "      <td>2020-03-12T15:28:00Z</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>UC69SwnuvoumrKy6giA6crnA</td>\n",
       "      <td>Bad News Reunion - Topic</td>\n",
       "      <td>44</td>\n",
       "      <td>19938</td>\n",
       "      <td>109</td>\n",
       "      <td>GqqS-5TOnwE</td>\n",
       "      <td>Coming Into Los Angeles (Live)</td>\n",
       "      <td>2020-03-12T15:28:00Z</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>UC69SwnuvoumrKy6giA6crnA</td>\n",
       "      <td>Bad News Reunion - Topic</td>\n",
       "      <td>44</td>\n",
       "      <td>19938</td>\n",
       "      <td>109</td>\n",
       "      <td>r_nRGqPKw48</td>\n",
       "      <td>Ill Go Crazy (Live)</td>\n",
       "      <td>2020-03-12T15:28:00Z</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>UC69SwnuvoumrKy6giA6crnA</td>\n",
       "      <td>Bad News Reunion - Topic</td>\n",
       "      <td>44</td>\n",
       "      <td>19938</td>\n",
       "      <td>109</td>\n",
       "      <td>CY0f0cVnH7A</td>\n",
       "      <td>The Thrill Is Gone (Live)</td>\n",
       "      <td>2020-03-12T15:27:59Z</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>UC69SwnuvoumrKy6giA6crnA</td>\n",
       "      <td>Bad News Reunion - Topic</td>\n",
       "      <td>44</td>\n",
       "      <td>19938</td>\n",
       "      <td>109</td>\n",
       "      <td>UwfP_AGJKqM</td>\n",
       "      <td>Cinnamon Girl (Live)</td>\n",
       "      <td>2020-03-12T15:27:59Z</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   channel_id             channel_title  subscriber_count  \\\n",
       "0    UCuTAXTexrhetbOe3zgskJBQ                   日テレNEWS           2780000   \n",
       "1    UCuTAXTexrhetbOe3zgskJBQ                   日テレNEWS           2780000   \n",
       "2    UCuTAXTexrhetbOe3zgskJBQ                   日テレNEWS           2780000   \n",
       "3    UCuTAXTexrhetbOe3zgskJBQ                   日テレNEWS           2780000   \n",
       "4    UCuTAXTexrhetbOe3zgskJBQ                   日テレNEWS           2780000   \n",
       "..                        ...                       ...               ...   \n",
       "216  UC69SwnuvoumrKy6giA6crnA  Bad News Reunion - Topic                44   \n",
       "217  UC69SwnuvoumrKy6giA6crnA  Bad News Reunion - Topic                44   \n",
       "218  UC69SwnuvoumrKy6giA6crnA  Bad News Reunion - Topic                44   \n",
       "219  UC69SwnuvoumrKy6giA6crnA  Bad News Reunion - Topic                44   \n",
       "220  UC69SwnuvoumrKy6giA6crnA  Bad News Reunion - Topic                44   \n",
       "\n",
       "     total_views  video_count     video_id  \\\n",
       "0     4050252948        72293  gBBdYhfWzKI   \n",
       "1     4050252948        72293  ZjwyCwbjdjU   \n",
       "2     4050252948        72293  vDoUL0qyV-g   \n",
       "3     4050252948        72293  MDFwyS8eyg0   \n",
       "4     4050252948        72293  ey8gEkH3D3U   \n",
       "..           ...          ...          ...   \n",
       "216        19938          109  GDHq0xd8xQo   \n",
       "217        19938          109  GqqS-5TOnwE   \n",
       "218        19938          109  r_nRGqPKw48   \n",
       "219        19938          109  CY0f0cVnH7A   \n",
       "220        19938          109  UwfP_AGJKqM   \n",
       "\n",
       "                                           video_title    video_published_at  \\\n",
       "0    米中関税協議で共同声明「１１５％引き下げ」合意の背景▽協議出席者の顔ぶれから見える双方の思惑...  2025-05-13T02:00:06Z   \n",
       "1    【最新 ニュースライブ】最新ニュースと生活情報（5月13日） ──THE LATEST NE...  2025-05-13T00:35:07Z   \n",
       "2    【国会中継】『参議院・財政金融委員会』チャットで語ろう！ ──政治ニュースライブ［2025年...  2025-05-12T09:56:19Z   \n",
       "3    【朝 ニュースライブ】最新ニュースと生活情報（5月13日） ──THE LATEST NEW...  2025-05-13T01:46:39Z   \n",
       "4                 【コメ価格】18週ぶり下落 「備蓄米」効果は？  社員にコメ配布の企業も  2025-05-12T23:14:19Z   \n",
       "..                                                 ...                   ...   \n",
       "216                            Young Girl Blues (Live)  2020-03-12T15:28:00Z   \n",
       "217                     Coming Into Los Angeles (Live)  2020-03-12T15:28:00Z   \n",
       "218                                Ill Go Crazy (Live)  2020-03-12T15:28:00Z   \n",
       "219                          The Thrill Is Gone (Live)  2020-03-12T15:27:59Z   \n",
       "220                               Cinnamon Girl (Live)  2020-03-12T15:27:59Z   \n",
       "\n",
       "     video_views  video_likes  video_comments  \n",
       "0            283            7               0  \n",
       "1           1482           11               0  \n",
       "2           1381           22               0  \n",
       "3          62472          144               0  \n",
       "4            938           15               6  \n",
       "..           ...          ...             ...  \n",
       "216           13            0               0  \n",
       "217           15            0               0  \n",
       "218           11            0               0  \n",
       "219            9            0               0  \n",
       "220           18            0               0  \n",
       "\n",
       "[221 rows x 11 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_top_news_videos()\n",
    "df.to_csv(\"top_news_videos.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65a7d239-8d97-45f2-b69f-004f2b94f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['日テレNEWS', 'にゅうちゅうぶ | NEWS official', 'Sky News', 'TVBS NEWS',\n",
       "       'ABS-CBN News', '9 News Australia', 'Geo News', 'Fox News',\n",
       "       'NBC News', 'ABC News', '無綫新聞 TVB NEWS Official', 'BBC News',\n",
       "       'NEWS AM', 'News - Topic', 'Local News Legend - Topic',\n",
       "       'Broken News - Topic', 'Good News Circle - Topic',\n",
       "       'Vida News - Topic', 'Good News Team - Topic', 'Good News - Topic',\n",
       "       'NEWS - Topic', 'The News Hinano - Topic', 'Great News - Topic',\n",
       "       'News from Neptune - Topic', 'News From Nowhere - Topic',\n",
       "       'Tierra Propia News - Topic', 'Hobo News - Topic',\n",
       "       'Public Spreads The News - Topic', 'Phokat News', 'aoen News',\n",
       "       'Violent News - Topic', 'Broadway News - Topic',\n",
       "       'Good News Everyone - Topic', 'John News - Topic',\n",
       "       'The News Channel - Topic', 'Shipping News - Topic',\n",
       "       'The Good News - Topic', 'News PrimeTime 24',\n",
       "       'Good News Music - Topic', 'TRUE LINE NEWS ',\n",
       "       'Animal News - Topic', 'THE NEWS - Topic', 'Future News - Topic',\n",
       "       'Bad News From Tony - Topic', 'Bad News Reunion - Topic'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['channel_title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ddc41-61d4-4710-8564-c5f54f833a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97540ec6-7e62-4604-8559-bc857a45e7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2f7ba-5150-43cc-809a-3053ec0075f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dc932-7a93-4a06-b68a-8dad3ac65113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c5abf-862a-43b9-9d40-e1de2ab5c06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5362f97b-9260-42cb-818d-f0cbc0d15fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日テレNEWS - UCuTAXTexrhetbOe3zgskJBQ\n",
      "にゅうちゅうぶ | NEWS official - UCj9f2amb1D0RuTNrBQ9GJoQ\n",
      "Sky News - UCoMdktPbSTixAyNGwb-UYkQ\n",
      "ABS-CBN News - UCE2606prvXQc_noEqKxVJXA\n",
      "TVBS NEWS - UC5nwNW4KdC0SzrhF9BXEYOQ\n",
      "9 News Australia - UCIYLOcEUX6TbBo7HQVF2PKA\n",
      "News - UCYfdidRxbB8Qhf0Nx7ioOYw\n",
      "Geo News - UC_vt34wimdCzdkrzVejwX9g\n",
      "Fox News - UCXIJgqnII2ZOINSWNOGFThA\n",
      "NBC News - UCeY0bbntWzzVIaj2z3QigXg\n",
      "ABC News - UCBi2mrWuNuyYy4gbM6fU18Q\n",
      "無綫新聞 TVB NEWS Official - UC_ifDTtFAcsj-wJ5JfM27CQ\n",
      "BBC News - UC16niRr50-MSBwiO3YDb3RA\n",
      "NEWS AM - UCDv-XtfgNGHXcpwu4ab0WnA\n",
      "News - Topic - UCte8ywmzIMWUT3K6rH4H1XQ\n",
      "Vida News - Topic - UCk6j5PWGPvpyYpKyYz7z91Q\n",
      "Good News Circle - Topic - UC79umPRGQIo23TpAyfpv48w\n",
      "Good News - Topic - UCrLbXfsTlSlU4eZYiAXNcsQ\n",
      "NEWS - Topic - UCbYM7oBcZNzqQp98PiF5HKw\n",
      "Great News - Topic - UCDAqPSrlnLSJJrjiI0eoHYw\n",
      "Health News - UCn371zWk5jljg-ycIXkEUSA\n",
      "News From Nowhere - Topic - UCvOJ4neMIuwsAvoNV82sCPA\n",
      "Tierra Propia News - Topic - UCkYvApoUkQR4oNh_vCN3JLA\n",
      "Hobo News - Topic - UC9Ik6IQd7ro2nhr3sI7wCNg\n",
      "Public Spreads The News - Topic - UCuP6ZfysEnrnxjcE4wvQ_rQ\n"
     ]
    }
   ],
   "source": [
    "# Print the channel info (you can modify this to display only the channel IDs and names)\n",
    "for channel in news_channels['items']:\n",
    "    channel_id = channel['snippet']['channelId']\n",
    "    channel_title = channel['snippet']['channelTitle']\n",
    "    print(f\"{channel_title} - {channel_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a547d60e-4761-44dd-8bd7-ddc438589776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part='snippet,statistics',\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    stats = response['items'][0]['statistics']\n",
    "    return {\n",
    "        'channel_id': channel_id,\n",
    "        'title': response['items'][0]['snippet']['title'],\n",
    "        'subscribers': stats.get('subscriberCount', 'hidden'),\n",
    "        'total_views': stats.get('viewCount'),\n",
    "        'video_count': stats.get('videoCount')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b6ce89e-be6b-4d6b-b7bd-f6f61d74bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uploads_playlist_id(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part='contentDetails',\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "def get_video_ids_from_playlist(playlist_id, max_videos=5):\n",
    "    video_ids = []\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=max_videos\n",
    "    )\n",
    "    response = request.execute()\n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd4eb8b8-6db0-465f-a899-cd5400633aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_stats(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,statistics',\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    data = response['items'][0]\n",
    "    return {\n",
    "        'title': data['snippet']['title'],\n",
    "        'published_at': data['snippet']['publishedAt'],\n",
    "        'views': data['statistics'].get('viewCount'),\n",
    "        'likes': data['statistics'].get('likeCount'),\n",
    "        'comments': data['statistics'].get('commentCount')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f25e74a3-6741-46cd-9ecb-e80cf9fc5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(video_id, max_comments=100000):\n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        maxResults=1000000,  # YouTube limits this per page\n",
    "        textFormat='plainText'\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "        comments.append({\n",
    "            'author': top_comment['authorDisplayName'],\n",
    "            'profile_image': top_comment['authorProfileImageUrl'],\n",
    "            'text': top_comment['textDisplay'],\n",
    "            'like_count': top_comment['likeCount'],\n",
    "            'published_at': top_comment['publishedAt']\n",
    "        })\n",
    "\n",
    "    return comments[:max_comments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "298874ed-b5c8-403a-a7eb-f798bc0392f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoID</th>\n",
       "      <th>VideoDate</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CommentTimestamp</th>\n",
       "      <th>Username</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cMe6JGJtAb8</td>\n",
       "      <td>2025-05-12T23:46:38Z</td>\n",
       "      <td>Really!? What trade deal? You mean he's going ...</td>\n",
       "      <td>2025-05-12T23:46:38Z</td>\n",
       "      <td>@Elcidro123</td>\n",
       "      <td>UC04TjoS58Xpzg9yAjuY-HGw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cMe6JGJtAb8</td>\n",
       "      <td>2025-05-12T23:43:41Z</td>\n",
       "      <td>Trade deal my arse! He’s back peddling fast as...</td>\n",
       "      <td>2025-05-12T23:43:41Z</td>\n",
       "      <td>@scamwatchdog</td>\n",
       "      <td>UCLRIrszWF_bAM28DW9_SCbQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cMe6JGJtAb8</td>\n",
       "      <td>2025-05-12T23:38:56Z</td>\n",
       "      <td>YA GREAT NEWS WE WENT BACK TO BEFORE THE TARIF...</td>\n",
       "      <td>2025-05-12T23:38:56Z</td>\n",
       "      <td>@ChrisVukadin</td>\n",
       "      <td>UCSwkbqwDZhQtL1y1hJM8CrA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cMe6JGJtAb8</td>\n",
       "      <td>2025-05-12T23:37:16Z</td>\n",
       "      <td>How many MAGA Republicans does it take to chan...</td>\n",
       "      <td>2025-05-12T23:37:16Z</td>\n",
       "      <td>@autodidactic-i2i</td>\n",
       "      <td>UCCbjpEd5vS_zEq4o7AglOLg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cMe6JGJtAb8</td>\n",
       "      <td>2025-05-12T23:36:13Z</td>\n",
       "      <td>Trump lies and Fox News swears to it. Fox News...</td>\n",
       "      <td>2025-05-12T23:36:13Z</td>\n",
       "      <td>@ctbigdog88</td>\n",
       "      <td>UCKn6jEfF1d9Z8BwcdA9yEwQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VideoID             VideoDate  \\\n",
       "0  cMe6JGJtAb8  2025-05-12T23:46:38Z   \n",
       "1  cMe6JGJtAb8  2025-05-12T23:43:41Z   \n",
       "2  cMe6JGJtAb8  2025-05-12T23:38:56Z   \n",
       "3  cMe6JGJtAb8  2025-05-12T23:37:16Z   \n",
       "4  cMe6JGJtAb8  2025-05-12T23:36:13Z   \n",
       "\n",
       "                                             Comment      CommentTimestamp  \\\n",
       "0  Really!? What trade deal? You mean he's going ...  2025-05-12T23:46:38Z   \n",
       "1  Trade deal my arse! He’s back peddling fast as...  2025-05-12T23:43:41Z   \n",
       "2  YA GREAT NEWS WE WENT BACK TO BEFORE THE TARIF...  2025-05-12T23:38:56Z   \n",
       "3  How many MAGA Republicans does it take to chan...  2025-05-12T23:37:16Z   \n",
       "4  Trump lies and Fox News swears to it. Fox News...  2025-05-12T23:36:13Z   \n",
       "\n",
       "            Username                    UserID  Likes  Dislikes  Replies  \\\n",
       "0        @Elcidro123  UC04TjoS58Xpzg9yAjuY-HGw    0.0       0.0      0.0   \n",
       "1      @scamwatchdog  UCLRIrszWF_bAM28DW9_SCbQ    0.0       0.0      0.0   \n",
       "2      @ChrisVukadin  UCSwkbqwDZhQtL1y1hJM8CrA    0.0       0.0      0.0   \n",
       "3  @autodidactic-i2i  UCCbjpEd5vS_zEq4o7AglOLg    0.0       0.0      0.0   \n",
       "4        @ctbigdog88  UCKn6jEfF1d9Z8BwcdA9yEwQ    0.0       0.0      0.0   \n",
       "\n",
       "  Timestamp Date  \n",
       "0       NaN  NaN  \n",
       "1       NaN  NaN  \n",
       "2       NaN  NaN  \n",
       "3       NaN  NaN  \n",
       "4       NaN  NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get replies for a specific comment\n",
    "def get_replies(youtube, parent_id, video_id): \n",
    "    replies = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        reply_request = youtube.comments().list(\n",
    "            part=\"snippet\",\n",
    "            parentId=parent_id,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        reply_response = reply_request.execute()\n",
    "\n",
    "        for item in reply_response['items']:\n",
    "            comment = item['snippet']\n",
    "            replies.append({\n",
    "                'Timestamp': comment['publishedAt'],\n",
    "                'Username': comment['authorDisplayName'],\n",
    "                'VideoID': video_id,\n",
    "                'Comment': comment['textDisplay'],\n",
    "                'Date': comment['updatedAt'] if 'updatedAt' in comment else comment['publishedAt'],\n",
    "                'UserID': comment['authorChannelId']['value']\n",
    "            })\n",
    "\n",
    "        next_page_token = reply_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return replies\n",
    "\n",
    "# Function to get all comments (including replies) for a single video\n",
    "def get_comments_for_video(youtube, video_id, max_comments=100):\n",
    "    all_comments = []\n",
    "    next_page_token = None\n",
    "    comments_fetched = 0\n",
    "\n",
    "    while True:\n",
    "        comment_request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100\n",
    "        )\n",
    "        comment_response = comment_request.execute()\n",
    "\n",
    "        for item in comment_response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comment_data = {\n",
    "                'VideoID': video_id,\n",
    "                'VideoDate': top_comment['publishedAt'],  # Date of the comment (same as video post time for top comment)\n",
    "                'Comment': top_comment['textDisplay'],\n",
    "                'CommentTimestamp': top_comment['publishedAt'],\n",
    "                'Username': top_comment['authorDisplayName'],\n",
    "                'UserID': top_comment.get('authorChannelId', {}).get('value'),  # User's channel ID\n",
    "                'Likes': top_comment.get('likeCount', 0),  # Likes on the comment\n",
    "                'Dislikes': 0,  # Dislike data is not provided by the API, so we assume 0.\n",
    "                'Replies': item['snippet']['totalReplyCount'],  # Number of replies to the comment\n",
    "            }\n",
    "\n",
    "            all_comments.append(comment_data)\n",
    "\n",
    "            # Fetch replies if there are any\n",
    "            if item['snippet']['totalReplyCount'] > 0:\n",
    "                all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
    "\n",
    "            comments_fetched += 1\n",
    "            if comments_fetched >= max_comments:\n",
    "                break\n",
    "\n",
    "        next_page_token = comment_response.get('nextPageToken')\n",
    "        if not next_page_token or comments_fetched >= max_comments:\n",
    "            break\n",
    "\n",
    "    # Convert the list of comments to a pandas DataFrame\n",
    "    comments_df = pd.DataFrame(all_comments)\n",
    "    return comments_df\n",
    "\n",
    "# Test the function on the provided video ID\n",
    "video_id = \"cMe6JGJtAb8\"\n",
    "comments_df = get_comments_for_video(youtube, video_id, max_comments=1000)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "comments_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c60e14a-231f-4829-82d9-d0da5443a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@FoxNews -> Read more: https://www.foxnews.com/politics/democrat-hank-johnson-draws-holocaust-comparison-while-b\n",
      "@rosesargent3098 -> I bet Democrats are on payroll follow the money\n",
      "@JacobMyers-g8y -> Hillary is on his hat\n",
      "@tompastian3447 -> You have to be mentally sick to support the democrat party today.\n",
      "@mikemigueis548 -> THANK GOD FOR THE GREAT TRUMP. NOBODY LIKE TRUMP.\n"
     ]
    }
   ],
   "source": [
    "comments = get_comments_for_video(video_ids[0], max_comments=5)\n",
    "for c in comments:\n",
    "    print(c['author'], \"->\", c['text'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5619874-c086-4cbe-b639-e121c61a1545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd54c2-06df-43f2-9b9a-32cad636436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d893da1-6d23-4474-8f8d-96515ff54398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbd449-b01e-4ea4-b4df-8d4a088ec05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f8d7c-ad6a-4ce5-96c8-c84f143402b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e6f9b-3756-4695-9d7e-985be814e03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ecf05-0bd9-40d1-932f-c8e6eae645c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687080a7-e9be-4d9e-a48a-b33ab3d180bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a53715-6d0f-4cf3-b740-3d481b6635f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7655e-dba6-4c14-ac97-5eeefeeb2e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37c2ec-b612-4728-8276-694f7387e077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857577df-aa65-49f1-96e9-96911a7f3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f749928-e2d6-4eb1-9017-a47d5feb835d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c214e8-d2c5-41d7-9436-6e2c3b2845fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2b181-0b04-48a1-b8ff-9fefc42cb816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1b681-235c-40a0-ad9d-c081930c82bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb83664-1a42-4d11-85a2-d954e934cff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8bbf0-8234-4ded-89fe-e090efe38930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
